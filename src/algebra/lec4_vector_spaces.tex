\begin{definition}
    \label{d:vector_space}
    Przestrzeń wektorowa (liniowa) nad ciałem $(K, \oplus, \otimes)$ to struktura $(V, K, +, \cdot)$, gdzie
    \begin{enumerate}[noitemsep,nolistsep]
        \item $(V, +)$ jest grupą abelową,
        \item działanie $\cdot : K \times V \lthen V$ jest zewnętrzne
        \item działanie $\cdot$ jest rozdzielne względem działania $+$, to znaczy
            $$ \dforall{u, v \in V} \dforall{\alpha \in K} \alpha\cdot(u + v) = (\alpha \cdot u) + (\alpha \cdot v), $$
        \item zachodzi ,,rozdzielność'' działania $\cdot$ względem $+$ i $\oplus$, to znaczy
            $$ \dforall{v \in V} \dforall{\alpha, \beta \in K} (\alpha \oplus \beta) \cdot v = (\alpha \cdot v) + (\beta \cdot v), $$
        \item zachodzi ,,łączność'' działań $\cdot$ i $\otimes$, to znaczy
            $$ \dforall{v \in V} \dforall{\alpha, \beta \in K} (\alpha \otimes \beta) \cdot v = \alpha \cdot (\beta \cdot v), $$
        \item jedynka z ciała $(K, \oplus, \otimes)$ jest elementem neutralnym również dla działania $\cdot$, to znaczy
            $$ \dforall{v \in V} \mathbf{1} \cdot v = v. $$
    \end{enumerate}
\end{definition}

Elementy zbioru $V$ nazywamy \vocab{wektorami}, a zbioru $K$ -- \vocab{skalarami}. Często zamiast przestrzeni $(V, K, +, \cdot)$ piszemy o przestrzeni $V$, a zamiast symboli $\oplus, \otimes$ piszemy po prostu $+, \cdot$. Element neutralny dodawania wektorów to wektor zerowy $\ol{0}$.

\begin{example}
    Przestrzenią wektorową nad ciałem liczb rzeczywistych jest struktura $(\RR^n, \RR, +, \cdot)$, często oznaczana jako $\RR^n(\RR)$, gdzie
    \begin{itemize}[noitemsep,nolistsep]
        \item $(x_1, x_2, \ldots, x_n) + (y_1, y_2, \ldots, y_n) = (x_1 + y_1, \ldots, x_n + y_n)$,
        \item $\alpha \cdot (x_1, x_2, \ldots, x_n) = (\alpha x_1, \alpha x_2, \ldots, \alpha x_n)$.
    \end{itemize}
\end{example}

\begin{example}
    Jeśli przez $\RR[x]_n$ oznaczymy zbiór wielomianów rzeczywistych o stopniu równym co najwyżej $n$, to struktura $$(\RR[x]_n, \RR, +, \cdot)$$
    będzie przestrzenią liniową.
\end{example}

\begin{theorem}
    W przestrzeni liniowej $(V, K, +, \cdot)$ dla każdych $u, v \in V$ oraz $\alpha, \beta \in K$ zachodzą następujące własności:
    \begin{enumerate}[noitemsep,nolistsep]
        \item $\mathbf{0} \cdot v = \ol{0}$,
        \item $\alpha \cdot \ol{0} = \ol{0}$,
        \item $(-\alpha) \cdot v = - (\alpha \cdot v)$,
        \item $\alpha \cdot (-v) = - (\alpha \cdot v)$,
        \item $\alpha \cdot v = \ol{0} \iff (\alpha = \mathbf{0} \lor v = \ol{0})$,
        \item $\alpha \cdot u = \alpha \cdot v \implies u = v$, dla $\alpha \neq \mathbf{0}$,
        \item $\alpha \cdot v = \beta \cdot v \implies \alpha = \beta$, dla $v \neq \ol{0}$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    W dowodach wszystkich własności posługujemy się wyłącznie definicją przestrzeni wektorowej (\ref{d:vector_space}), wektora zerowego oraz poprzednimi w kolejności udowadnianymi własnościami.
    \begin{enumerate}[noitemsep,nolistsep]
        \item $\begin{aligned}[t]
            v + \mathbf{0} \cdot v &= \mathbf{1} \cdot v + \mathbf{0} \cdot v = (\mathbf{1} + \mathbf{0}) \cdot v = v = v + \ol{0} \\
            \therefore \mathbf{0} \cdot v &= \ol{0}
            \end{aligned}$
        \item $\begin{aligned}[t]
            \alpha \cdot \ol{0} &= \alpha \cdot (\ol{0} + \ol{0}) = \alpha \cdot \ol{0} + \alpha \cdot \ol{0} \\
            \therefore \ol{0} &= \alpha \cdot \ol{0}
            \end{aligned}$
        \item $\begin{aligned}[t]
            \ol{0} = \alpha \cdot v - (\alpha \cdot v) &\text{ oraz } \ol{0} = \mathbf{0} \cdot v = (\alpha - \alpha) \cdot v = \alpha \cdot v + (-\alpha) \cdot v \\
            \therefore -(\alpha \cdot v) &= (-\alpha) \cdot v
            \end{aligned}$
        \item $\begin{aligned}[t]
            \ol{0} = \alpha \cdot v - (\alpha \cdot v) &\text{ oraz } \ol{0} = \alpha \cdot \ol{0} = \alpha \cdot (v - v) = \alpha \cdot v + \alpha \cdot (-v) \\
            \therefore -(\alpha \cdot v) &= \alpha \cdot (-v)
            \end{aligned}$
        \item implikacja $\Leftarrow$ (konieczność) trywialna; implikacja $\Rightarrow$ (dostateczność) wynika z tego, że jeśli założymy, że $\alpha \neq \mathbf{0}, v \neq \ol{0}$, to mamy
            $$ \alpha \cdot (u + v) = \alpha \cdot u + \alpha \cdot v = \alpha \cdot u. $$
            Mnożąć przez $a^{-1}$ (które istnieje, bo $(K, +, \cdot)$ jest ciałem) otrzymujemy
            $$ u + v = u, $$
            a dodając obustronnie $-u$ (które istnieje z definicji \ref{d:vector_space}) dochodzimy do sprzeczności z założeniem
            $$ v = \ol{0}. $$
        \item dowód analogiczny do dowodu lematu \ref{l:cancellation_property},
        \item dowód analogiczny do dowodu lematu \ref{l:cancellation_property}.
    \end{enumerate}
\end{proof}

\begin{definition}
    Podprzestrzeń liniowa $(U, K, +, \cdot)$ to taka struktura, że
    \begin{enumerate}[noitemsep,nolistsep]
        \item $(V, K, +, \cdot)$ jest przestrzenią liniową oraz $U \subset V, U \neq \emptyset$,
        \item $\dforall{u, v \in U} (u + v) \in U$,
        \item $\dforall{\alpha \in K} \dforall{u \in U} (\alpha \cdot u) \in U$.
    \end{enumerate}
\end{definition}

\begin{fact}[Równoważna charakterystyka podprzestrzeni]
    Dwa ostatnie warunki z powyższej definicji są równoważne warunkowi:
    $$ \dforall{\alpha, \beta \in K} \dforall{u, v \in V} \alpha \cdot u + \beta \cdot v \in U. $$
\end{fact}
\begin{proof}
    Implikacja w jedną stroną jest trywialna, w drugą stronę można ją udowodnić przez stwierdzenie, że każdy wektor ma wektor przeciwny (bo z definicji \ref{d:vector_space} $(V, +)$ jest grupą abelową) oraz że pod $\alpha, \beta$ można podstawić $\mathbf{1}$ (i znowu użyć definicji \ref{d:vector_space}).
\end{proof}

\begin{definition}
    Kombinacja liniowa wektorów $v_1, v_2, \ldots, v_n$ to wektor
    $$ \alpha_1v_1 + \alpha_2v_2 + \ldots + \alpha_nv_n, $$
    gdzie skalary $\alpha_1, \alpha_2, \ldots, \alpha_n$ nazywamy współczynnikami tej kombinacji.
\end{definition}

\begin{definition}
    Wektory $v_1, v_2, \ldots, v_n$ są liniowo niezależne, jeśli dla każdego ciągu współczynników $\alpha$ zachodzi implikacja
    $$ \alpha_1v_1 + \alpha_2v_2 + \ldots + \alpha_nv_n = \ol{0} \implies \alpha_1, \alpha_2, \ldots, \alpha_n = 0. $$
\end{definition}
Mówimy również, że wektory są liniowo zależne, jeśli nie są liniowo niezależne.

\begin{example}
    W przestrzeni wektorowej $\RR^3(\RR)$ weźmy wektory
    $$ u = (3, 2, -1), v = (1, -2, 1), w = (1, 1, 1). $$
    Rozwiązujemy układ równań $\alpha u + \beta v + \gamma w = \ol{0} \implies$
    \begin{equation*}
        \begin{cases}
            3\alpha + \beta + \gamma = 0 \\
            2\alpha - 2\beta + \gamma = 0 \\
            -\alpha + \beta + \gamma = 0
        \end{cases} \implies
        \begin{cases}
            4\alpha = 0 \\
            2\alpha - 2\beta + \gamma = 0 \\
            -\alpha + \beta + \gamma = 0
        \end{cases} \implies
        \begin{cases}
            \alpha = 0 \\
            - 2\beta + \gamma = 0 \\
            \beta + \gamma = 0
        \end{cases} \implies
        \begin{cases}
            \alpha = 0 \\
            \beta = 0 \\
            \gamma = 0
        \end{cases}
    \end{equation*}
    pokazując, że wektory $u, v, w$ są liniowo niezależne.
\end{example}

\begin{theorem}
    Wektory $v_1, \ldots, v_n$ są liniowo zależne wtedy i tylko wtedy, gdy przynajmniej jeden jest kombinacją liniową pozostałych.
\end{theorem}
\begin{proof}
    Jeśli istnieje taki ciąg $\alpha_1, \alpha_2, \ldots, \alpha_n$, że $\{\alpha_1, \ldots, \alpha_n\} \neq \{0\}$ oraz
    $$ \alpha_1v_1 + \alpha_2v_2 + \ldots + \alpha_nv_n = \ol{0}, $$
    to bez starty ogólności możemy przyjąć, że $\alpha_n \neq 0$. Równoważnie przekształcamy równość do postaci
    $$ \alpha_1v_1 + \alpha_2v_2 + \ldots + \alpha_{n-1}v_{n-1} = -\alpha_nv_n $$
    $$ \frac{-\alpha_1}{\alpha_n}v_1 + \frac{-\alpha_2}{\alpha_n}v_2 + \ldots + \frac{-\alpha_{n-1}}{\alpha_n}v_{n-1} = v_n, $$
    więc otrzymujemy równoważność między założeniem i stwierdzeniem, że $v_n$ jest kombinacją liniową wektorów $\alpha_1, \ldots, \alpha_{n-1}$.
\end{proof}

\begin{theorem}
    Jeśli wektory $v_1, v_2, \ldots, v_n$ są liniowo niezależne oraz wektor $u$ jest kombinacją liniową tych wektorów, to współczynniki tej kombinacji są wyznaczone jednoznacznie.
\end{theorem}
\begin{proof}
    Weźmy takie ciągi $(\alpha_n)$ i $(\beta_n)$, że
    \begin{align*}
        u = \alpha_1v_1 + \alpha_2v_2 + \ldots + \alpha_nv_n \\
        u = \beta_1v_1 + \beta_2v_2 + \ldots + \beta_nv_n
    \end{align*}
    Mamy
    $$ u - u = \ol{0} = (\alpha_1 - \beta_1)v_1 + (\alpha_2 - \beta_2)v_2 + \ldots + (\alpha_n - \beta_n)v_n $$
    co, skoro $v_1, v_2, \ldots, v_n$ są liniowo niezależne, dowodzi, że dla każdego $i$ zachodzi $\alpha_i - \beta_i = 0$, więc ciągi $(\alpha_n)$ i $(\beta_n)$ są równe.
\end{proof}